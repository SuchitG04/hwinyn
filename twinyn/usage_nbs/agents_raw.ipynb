{
 "cells": [
  {
   "cell_type": "code",
   "id": "6e96906a571403f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T08:19:30.009088Z",
     "start_time": "2024-08-31T08:19:29.086061Z"
    }
   },
   "source": [
    "from twinyn.agents.prompts import *\n",
    "\n",
    "import os\n",
    "import psycopg2\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from autogen import ConversableAgent, AssistantAgent\n",
    "from autogen.coding import LocalCommandLineCodeExecutor\n",
    "from autogen.coding.func_with_reqs import with_requirements\n",
    "load_dotenv()\n",
    "\n",
    "work_dir = Path(\"coding\")\n",
    "work_dir.mkdir(exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "484ccaa9-d4d7-4d11-8b7d-a3941d3585f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T08:19:32.385830Z",
     "start_time": "2024-08-31T08:19:30.932048Z"
    }
   },
   "source": [
    "import agentops\n",
    "agentops.init(os.getenv(\"AGENTOPS_API_KEY\"))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps: \u001B[34m\u001B[34mSession Replay: https://app.agentops.ai/drilldown?session_id=1d68f9eb-8463-411f-b350-2e8035242241\u001B[0m\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<agentops.session.Session at 0x741df5b573e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "13c1aae8386006c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T08:19:33.290597Z",
     "start_time": "2024-08-31T08:19:33.287590Z"
    }
   },
   "source": [
    "@with_requirements(python_packages=[\"psycopg2\"], global_imports=[\"psycopg2\", \"os\"])\n",
    "def execute_sql(query: str) -> list:\n",
    "    \"\"\"Execute SQL statement and return a list of results. Does NOT print the results.\"\"\"\n",
    "    conn = psycopg2.connect(os.getenv(\"CONNECTION_URL\"))\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(\n",
    "            query\n",
    "        )\n",
    "        res = cursor.fetchall()\n",
    "        return res"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "116f07604fae5c1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T08:19:35.657775Z",
     "start_time": "2024-08-31T08:19:33.531269Z"
    }
   },
   "source": [
    "\n",
    "# TODO:\n",
    "# - include multiple seed prompts\n",
    "# - aggregate and manage results, analysis, and instructions from all the seed prompts\n",
    "# - 2nd order analysis from these resultant artifacts\n",
    "# - a nice API also maybe?\n",
    "\n",
    "executor = LocalCommandLineCodeExecutor(work_dir=work_dir, functions=[execute_sql])\n",
    "seed_prompts = [\n",
    "    \"Peak traffic time in the past 5 hours bucketed in 30 minute intervals\",\n",
    "    \"Requests by country in the past 5 hours\"\n",
    "]\n",
    "\n",
    "SQL_AGENT_SYSTEM_PROMPT += executor.format_functions_for_prompt()\n",
    "\n",
    "# SQL agent who's sole purpose is to write SQL queries and write python code to execute it (using the `execute_sql` function).\n",
    "sql_agent = ConversableAgent(\n",
    "    name=\"sql_agent\",\n",
    "    system_message=SQL_AGENT_SYSTEM_PROMPT,\n",
    "    # set \"cache_seed\" to None to NOT use cached responses to same queries\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.getenv(\"OPENAI_API_KEY\"), \"price\": [0.00250, 0.01]}]},\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# a code executor agent, as the name indicates. no LLM is configured for this agent.\n",
    "code_executor_agent = ConversableAgent(\n",
    "    name=\"code_executor_agent\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"), # is not called further when TERMINATE is recieved\n",
    "    llm_config=False,\n",
    "    code_execution_config={\n",
    "        \"executor\": executor,\n",
    "    },\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# an analyst agent that gives \"Analysis\" and \"Further Instructions\" based on the output from the `sql_agent`'s query output.\n",
    "analyst_agent = AssistantAgent(\n",
    "    name=\"analyst_agent\",\n",
    "    system_message=ANALYST_AGENT_SYSTEM_PROMPT,\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.getenv(\"OPENAI_API_KEY\"), \"price\": [0.000150, 0.000600]}]},\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "3630c5b9f1102a02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T08:19:35.666994Z",
     "start_time": "2024-08-31T08:19:35.663018Z"
    }
   },
   "source": [
    "\n",
    "# TODO:\n",
    "# - evaluate if this functions works as expected. expectation: take both the execution output (given by `code_executor_agent`)\n",
    "#   and the response to the output (which also contains TERMINATE) by `sql_agent` as carryover to the `analyst_agent`\n",
    "def custom_message(sender: ConversableAgent, recipient: ConversableAgent, context: dict) -> str | dict:\n",
    "    carryover = context.get(\"carryover\", \"\")\n",
    "    if isinstance(carryover, list):\n",
    "        carryover = '\\n'.join(carryover[-3:])\n",
    "    final_msg = \"What do you think of the results? Do you find any peculiarity or anything that require further querying?\" + \"\\nContext: \\n\" + carryover\n",
    "    return final_msg"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T08:19:50.250295Z",
     "start_time": "2024-08-31T08:19:35.718439Z"
    }
   },
   "source": [
    "\n",
    "# kicks off execution with the `code_executor_agent` calling `sql_agent` with the seed_prompt\n",
    "# more info: https://microsoft.github.io/autogen/docs/tutorial/conversation-patterns#sequential-chats\n",
    "# api-ref: https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent#initiate_chats and #initiate_chat\n",
    "chat_results = []\n",
    "for seed_prompt in seed_prompts[:1]:\n",
    "    chat_results.append(\n",
    "        code_executor_agent.initiate_chats(\n",
    "            [\n",
    "                {\n",
    "                    \"recipient\": sql_agent,\n",
    "                    \"message\": seed_prompt,\n",
    "                    \"clear_history\": True,\n",
    "                    \"silent\": False,\n",
    "                    \"max_turns\": None, # indicates to wait till \"TERMINATE\" is sent by this agent\n",
    "                    \n",
    "                    \"summary_method\": \"last_msg\"\n",
    "                },\n",
    "                {\n",
    "                    \"recipient\": analyst_agent,\n",
    "                    \"message\": custom_message,\n",
    "                    \"max_turns\": 1,\n",
    "                    \"summary_method\": \"last_msg\",\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\n",
      "********************************************************************************\u001B[0m\n",
      "\u001B[34mStarting a new chat....\u001B[0m\n",
      "\u001B[34m\n",
      "********************************************************************************\u001B[0m\n",
      "\u001B[33mcode_executor_agent\u001B[0m (to sql_agent):\n",
      "\n",
      "Peak traffic time in the past 5 hours bucketed in 30 minute intervals\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33msql_agent\u001B[0m (to code_executor_agent):\n",
      "\n",
      "To identify the peak traffic times in the past 5 hours, we can aggregate the data from the server_log table by counting the number of requests in 30-minute intervals. We'll also need to consider the last request time to define the starting point for our 5-hour period.\n",
      "\n",
      "Hereâ€™s the plan:\n",
      "\n",
      "1. Retrieve the last request time from the server_log to set the reference for our 5-hour window.\n",
      "2. Generate a series of 30-minute intervals within that 5-hour window.\n",
      "3. Count the requests in each interval, grouping them appropriately.\n",
      "4. Sort the results to find the intervals with the highest number of requests.\n",
      "\n",
      "Now I'll write the SQL query to achieve this.\n",
      "\n",
      "```python\n",
      "from functions import execute_sql\n",
      "\n",
      "query = \"\"\"\n",
      "WITH last_request AS (\n",
      "    SELECT MAX(datetime) AS last_time\n",
      "    FROM server_log\n",
      "),\n",
      "time_intervals AS (\n",
      "    SELECT generate_series(\n",
      "        (SELECT last_time - interval '5 hour' FROM last_request),\n",
      "        (SELECT last_time FROM last_request),\n",
      "        interval '30 minute'\n",
      "    ) AS interval_start\n",
      "),\n",
      "request_counts AS (\n",
      "    SELECT \n",
      "        ti.interval_start,\n",
      "        COUNT(sl.client) AS request_count\n",
      "    FROM\n",
      "        time_intervals ti\n",
      "    LEFT JOIN\n",
      "        server_log sl ON sl.datetime >= ti.interval_start AND sl.datetime < ti.interval_start + interval '30 minute'\n",
      "    GROUP BY \n",
      "        ti.interval_start\n",
      "    ORDER BY \n",
      "        request_count DESC\n",
      ")\n",
      "SELECT * \n",
      "FROM request_counts\n",
      "LIMIT 10;\n",
      "\"\"\"\n",
      "\n",
      "results = execute_sql(query)\n",
      "print(results)\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\u001B[0m\n",
      "\u001B[33mcode_executor_agent\u001B[0m (to sql_agent):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: [(datetime.datetime(2019, 1, 22, 10, 33, 17, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800))), 54811), (datetime.datetime(2019, 1, 22, 10, 3, 17, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800))), 43001), (datetime.datetime(2019, 1, 22, 9, 33, 17, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800))), 31407), (datetime.datetime(2019, 1, 22, 9, 3, 17, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800))), 19233), (datetime.datetime(2019, 1, 22, 8, 33, 17, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800))), 11292), (datetime.datetime(2019, 1, 22, 8, 3, 17, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800))), 8697), (datetime.datetime(2019, 1, 22, 6, 33, 17, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800))), 7953), (datetime.datetime(2019, 1, 22, 7, 33, 17, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800))), 7748), (datetime.datetime(2019, 1, 22, 7, 3, 17, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800))), 7099), (datetime.datetime(2019, 1, 22, 6, 3, 17, tzinfo=datetime.timezone(datetime.timedelta(seconds=19800))), 6770)]\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33msql_agent\u001B[0m (to code_executor_agent):\n",
      "\n",
      "The output of the query shows the peak traffic times in the past 5 hours bucketed in 30-minute intervals. Here are the intervals along with their corresponding request counts:\n",
      "\n",
      "1. 2019-01-22 10:33:17 UTC - 54811 requests\n",
      "2. 2019-01-22 10:03:17 UTC - 43001 requests\n",
      "3. 2019-01-22 09:33:17 UTC - 31407 requests\n",
      "4. 2019-01-22 09:03:17 UTC - 19233 requests\n",
      "5. 2019-01-22 08:33:17 UTC - 11292 requests\n",
      "6. 2019-01-22 08:03:17 UTC - 8697 requests\n",
      "7. 2019-01-22 06:33:17 UTC - 7953 requests\n",
      "8. 2019-01-22 07:33:17 UTC - 7748 requests\n",
      "9. 2019-01-22 07:03:17 UTC - 7099 requests\n",
      "10. 2019-01-22 06:03:17 UTC - 6770 requests\n",
      "\n",
      "This data shows the most active 30-minute intervals for requests received during the specified time frame.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[34m\n",
      "********************************************************************************\u001B[0m\n",
      "\u001B[34mStarting a new chat....\u001B[0m\n",
      "\u001B[34m\n",
      "********************************************************************************\u001B[0m\n",
      "\u001B[33mcode_executor_agent\u001B[0m (to analyst_agent):\n",
      "\n",
      "What do you think of the results? Do you find any peculiarity or anything that require further querying?\n",
      "Context: \n",
      "The output of the query shows the peak traffic times in the past 5 hours bucketed in 30-minute intervals. Here are the intervals along with their corresponding request counts:\n",
      "\n",
      "1. 2019-01-22 10:33:17 UTC - 54811 requests\n",
      "2. 2019-01-22 10:03:17 UTC - 43001 requests\n",
      "3. 2019-01-22 09:33:17 UTC - 31407 requests\n",
      "4. 2019-01-22 09:03:17 UTC - 19233 requests\n",
      "5. 2019-01-22 08:33:17 UTC - 11292 requests\n",
      "6. 2019-01-22 08:03:17 UTC - 8697 requests\n",
      "7. 2019-01-22 06:33:17 UTC - 7953 requests\n",
      "8. 2019-01-22 07:33:17 UTC - 7748 requests\n",
      "9. 2019-01-22 07:03:17 UTC - 7099 requests\n",
      "10. 2019-01-22 06:03:17 UTC - 6770 requests\n",
      "\n",
      "This data shows the most active 30-minute intervals for requests received during the specified time frame.\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33manalyst_agent\u001B[0m (to code_executor_agent):\n",
      "\n",
      "Analysis:\n",
      "The provided data indicates a significant spike in requests during the 30-minute interval of 10:33:17 UTC, with 54,811 requests. This peak is approximately 27% higher than the requests in the second-most active interval at 10:03:17 UTC, which had 43,001 requests. The traffic appears to be relatively low in earlier intervals, suggesting a possible event or activity that caused the surge in demand during this specific time. Furthermore, the decrease in request counts as we move to earlier intervals indicates an increasing trend in activity leading up to the peak.\n",
      "\n",
      "This analysis suggests that there may have been a specific event, promotional activity, or external factor influencing user engagement during the peak time. It would be beneficial to explore the nature of the requests made during that interval to ascertain what drove the traffic.\n",
      "\n",
      "Further Instructions:\n",
      "1. Query the `server_log` table to retrieve details of all requests made during the peak interval (2019-01-22 10:33:17 UTC) and analyze the methods, paths, and user agents used.\n",
      "2. Retrieve the status codes and sizes of responses from the `server_log` table for the peak interval to assess the quality and performance of the requests made.\n",
      "3. Investigate whether there are any geographically significant users contributing to the peak requests by joining the `geoip2_network` table with the `server_log` table based on the client CIDR.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "97016db448ed837b",
   "metadata": {},
   "source": [
    "Note: gpt-4o works the best for SQL queries. mini is shit"
   ]
  },
  {
   "cell_type": "code",
   "id": "79ff4043-d55a-4a92-8282-8113c03a6518",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T08:21:10.483686Z",
     "start_time": "2024-08-31T08:21:08.679817Z"
    }
   },
   "source": [
    "agentops.end_session(\"Success\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps: This run's cost $0.000443\n",
      "ðŸ–‡ AgentOps: \u001B[34m\u001B[34mSession Replay: https://app.agentops.ai/drilldown?session_id=1d68f9eb-8463-411f-b350-2e8035242241\u001B[0m\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce65fca9b31d308d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T07:44:25.859359Z",
     "start_time": "2024-08-29T07:44:25.854307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'The peak traffic time in the past 5 hours, bucketed in 30-minute intervals, was on January 22, 2019, at 11:01 AM with a total of 3815 requests.\\n\\nTERMINATE',\n",
       " 'role': 'user'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_results[0][0].chat_history[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981f992d-7c0b-45fd-badc-f343b40dcc21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac8bc3-845f-4a0d-a742-514454f04e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8446071c-fe93-4027-9585-ff4513981270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
